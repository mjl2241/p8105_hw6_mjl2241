---
title: "HW6"
output: github_document
editor_options: 
  chunk_output_type: inline
---
This is my response to HW 6:
```{r setup, include=FALSE}
library(tidyverse)
library(readr)
library(broom)
library(modelr)
library(mgcv)
library(MASS)
library(dbplyr)
library(rnoaa)
library(glmnet)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```
### Problem 1
We start off by downloading the data from The Washing Post, on on homicides in 50 large U.S. cities via Github. After taking a look at the dataset, we also created city_state variable and a binary variable indicating whether the homicide is solved.
```{r}
homicide_df =
  read.csv(url("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")) %>%
  janitor::clean_names() 

skimr::skim(homicide_df)
  
homicide_df$city_state= 
  paste(homicide_df$city,",", homicide_df$state)

#drop certain cities
homicide_df = 
  homicide_df %>%
    filter(!(city_state %in% c("Dallas , TX", "Phoenix , AZ", "Kansas City , MO", "Tulsa , AL"))) %>% 
#drop rows not containing white or black in victim_race
  filter(victim_race == "White" | victim_race == "Black") %>%
#relevel the races
   mutate(
    victim_race=fct_relevel(victim_race, "White"),
#create a binary resolved variable
  resolved = as.numeric(disposition == 'Closed by arrest'), 
         victim_age=as.numeric(victim_age)) #change victim age as numeric
```
For the city of Baltimore, MD...  
``` {r baltimore}
baltimore_df = 
  homicide_df %>%
  filter(city == "Baltimore") %>%
  dplyr::select(resolved, victim_age, victim_sex, victim_race)
```
using glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors. 
``` {r create a logistic regression with glm function}
fit_logistic = 
  baltimore_df %>%
  glm(resolved ~victim_age + victim_race + victim_sex, data =.,
      family = binomial()) %>%
  broom::tidy()
```
Obtaining the estimate, OR, CI of OR for solving homicides comparing non-white victims to white victims keeping all other variables fixed:
```{r table}
fit_logistic %>%
  mutate(OR = exp(estimate)) %>%
#add CI
  group_by(term) %>%
  mutate(
    ci_lower = exp(estimate - std.error * 1.96),
    ci_upper =  exp(estimate + std.error * 1.96)) %>%
  dplyr::select(term, log_OR = estimate, OR, ci_lower, ci_upper, p.value) %>% 
  knitr::kable(digits = 3)
```
Interpretation:
Homicides in which the victim is black are substantially less likely to be resolved that those in which the victim is white. Homicides in which the victim is male are significantly less like to be resolved than those in which the victim is female.The effect of age is statistically significant, and should be studied further.

Now run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing Black victims to white victims. Do this within a “tidy” pipeline, making use of purrr::map, list columns, and unnest as necessary to create a dataframe with estimated ORs and CIs for each city.

``` {r}
glm_cities =
  homicide_df %>% 
  group_by(city_state) %>%
  dplyr::select(city_state, resolved, victim_age, victim_sex, victim_race) %>%
  nest(data = -city_state) %>%
  mutate(
    models = map(data, ~glm(resolved ~victim_age + victim_race + victim_sex, data =.x, family = binomial)),
    results = map(models, broom::tidy)) %>% 
  dplyr::select(-data, -models) %>% 
  unnest(results) %>%
#add CI, OR
  group_by(term) %>%
  mutate(
    ci_lower = exp(estimate - std.error * 1.96),
    ci_upper =  exp(estimate + std.error * 1.96),
    OR = exp(estimate)) %>%
  dplyr::select(city_state, term, log_OR = estimate, OR, ci_lower, ci_upper, p.value) %>%
  filter(term == "victim_raceBlack") %>% 
  mutate(city_state = forcats::fct_reorder(factor(city_state), OR)) 
```
Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.
``` {r plot for results_df}
glm_cities  %>% 
  ggplot(aes(x = city_state, y = OR)) +
  geom_point(size=5) + 
  geom_errorbar(aes(x=city_state, ymin = ci_lower, ymax = ci_upper)) +
  theme(text = element_text(size = 8), axis.text.x = element_text(angle = 60, hjust = 1)) + 
   #Add the title and the name for x and y axis. 
  labs(
    title = "OR estimation of unsolved black homicides by city, state",
    x = "City, State",
    y = "Estimation of OR of unsolved Black homicides"
  )
```
Based on the graph above, Boston, MA had the lowest odds ratio compared to other major cities, meanwhile,
Tampa, Florida had the highest odds ratio of unsolved black homicides. This graph illustrates the odds of solving homicides in 50 major cities significantly differ based on victim's race.

### Problem 2
Import data & load and clean the data for regression analysis 
``` {r import dataset}
bw=
  read.csv("./birthweight.csv") %>%
  janitor::clean_names() %>%
   mutate(babysex = as.factor(babysex),
          malform = as.factor(malform),
          mrace = as.factor(mrace),
          frace = as.factor(frace))
skimr::skim(bw)
```
For this dataset, babysex, malform, mrace, and frace were converted to factors. The dataset of child birth weight contains 20 columns and 4342 rows. 

I'll use stepwise to build a model for birthweight. 
```{r regression model}
# Fit the full model 
full.model <- lm(bwt ~., data = bw)
# Stepwise regression model
step.model = stepAIC(full.model, direction = "both", 
                      trace = FALSE)
```
The result indicated that 11 predictors, including babysex2 (female), bhead, blength, delwt, fincome, gaweeks, mheight, mrace2(black), mrace3(Asian), mrace4(Puerto Rian), parity, ppwt, and smoken were significant predictors. 
```{r}
#Final model:
final_model = 
  lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data = bw) 
final_model %>%
  broom::tidy ()
summary(final_model)
```
And now onto plotting of model residuals against fitted values – using add_predictions and add_residuals in making this plot.
```{r}
bw %>% 
  modelr::add_residuals(final_model) %>%
  modelr::add_predictions(final_model) %>%
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() +
  labs(
    title = "Model Residuals v.s. Fitted Values",
    x = "Predicted values",
    y = "Residuals"
  )
```
#### About the model

I propose the above final model, based on stepwise regression selection. The variables seem reasonable predictors for babyweight, especially the baby gender, length, and gestational age(in weeks). The output shows that R^2 is 0.71, indicating that these 11 predictors (babysex2 (female), bhead, blength, delwt, fincome, gaweeks, mheight, mrace2(black), mrace3(Asian), mrace4(Puerto Rian), parity, ppwt, and smoken) explain 71% of the variance in birthweight. Based on the plot, we can see that when the prediction value is relatively small, the residual tend to be higher and the model does not have an accurate predication. When the prediction value is greater than 2000, the residuals become small and the prediction of the model is more accurate. This plot shows that the model violates the normal distribution of residual errors and homogeneity of residual variance.
```{r comparing to two others}
#other 3 models
model_2 = 
  lm(bwt ~ blength + gaweeks, data = bw) 
model_2%>%
  broom::tidy ()
model_3 = 
  lm(bwt ~ bhead*blength*babysex, data = bw) 
model_3%>%
  broom::tidy ()
```
#### Comparing models
```{r}
cv_df =
  crossv_mc(bw, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
cv_df = 
  cv_df %>% 
  mutate(
    final_model = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data = .x)),
    model_2 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_3 = map(train, ~lm(bwt ~ bhead*blength*babysex, data = .x))) %>% 
  mutate(
    rmse_final_model = map2_dbl(final_model, test, ~rmse(model = .x, data = .y)),
    rmse_model_2 = map2_dbl(model_2, test, ~rmse(model = .x, data = .y)),
    rmse_model_3 = map2_dbl(model_3, test, ~rmse(model = .x, data = .y))) 
```
#### plot the prediction error distribution
```{r}
cv_df %>% 
  dplyr::select(starts_with("rmse")) %>%
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```
Based on the violin plot of the three models, the final model has the lowest root mean square error and model 2 had the largest root-mean square error. Hence, the final model had the best performance, compared to other 2 models. 

### Problem 3
first import data
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
    dplyr::select(name, id, everything())

set.seed(1)
```
we will not use the bootstrap to examine the distribution of \hat{r}^2and log(\hat{\beta}_0*\hat{\beta}_1):using 5000 bootstrap samples and, for each bootstrap sample, produce estimates of these two quantities. 
```{r}
boot_strap = 
  weather_df %>% 
  bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap,~ lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy),
    results_2 = map(models, broom::glance)) %>% 
  dplyr::select(-strap, -models) %>% 
  unnest(results, results_2) %>% 
  dplyr::select(.id, term, estimate, r.squared) %>% 
  pivot_wider(
    names_from = "term",
    values_from = "estimate"
  ) %>% 
  janitor::clean_names() %>% 
  mutate(
    log_int= log(intercept * tmin)
  )
```
Plot of the distribution of \hat{r}^2:
```{r}
boot_strap  %>%
  ggplot(aes(x=r_squared))+
  geom_density()+
  xlab("Estimated r squared")
```
The \hat{r}^2 plot shows a normal distribution with a mean value around 0.91, indicating that the overall values of \hat{r}^2 were high and the model had a good performance.

plotting the distribution of log(\hat{\beta}_0*\hat{\beta}_1):,
```{r}
boot_strap  %>%
  ggplot(aes(x=log_int))+
  geom_density()+
  xlab("Log(Beta_0 x Beta_1)")
```
The log(\hat{\beta}_0*\hat{\beta}_1) plot shows a normal distribution with a mean value around 2.015.

2.5% and 07.5% quantiles for \hat{r}^2 and log(\hat{\beta}_0*\hat{\beta}_1):
```{r}
ci_r = boot_strap  %>%
  pull(r_squared) %>%
  quantile(c(0.025, 0.975))

ci_int = boot_strap  %>%
  pull(log_int) %>%
  quantile(c(0.025, 0.975))
```

The 95% confidence interval for \hat{r}^2 is 0.893 and 0.927. The 95% CI for log(\hat{\beta}_0*\hat{\beta}_1) is 1.96, 20.05